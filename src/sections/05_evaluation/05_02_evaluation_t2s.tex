\subsection{Sprachsynthese}

In diesem Kapitel wird entschieden, mit welcher Technologie das Feature Sprachsynthese umgesetzt wird.
Das Feature fordert, dass das System das Vorlesen empfangener Benachrichtigungen unterstützt.
Um dies zu ermöglichen, muss eine Technologie integriert werden, die es erlaubt Sprachdaten aus Textinhalten zu synthetisieren.
Diese Sprachdaten müssen als Audiodateien von der iOS Applikation abgespielt werden können.

Diese Anforderungen können mit den Standardbibliotheken für iOS-Entwicklung oder durch die Anbindung eines externen Anbieters umgesetzt werden.
Die Anbindung eines externen Anbieters kann direkt im Mobile Client implementiert werden.
Alternativ kann die Serverkomponente Cloudservice an einen Anbieter angebunden werden.
So kann der Cloudservice allen Clients eine einheitliche Schnittstelle bieten, um diese Daten abzufragen.

\subsubsection{Apple Speech Synthesis}

Die iOS Standardbibliothek bietet Komponenten zur Konvertierung von Text zu Sprache~\cite{ios_speech_synthesis}.
Die Verwendung dieser Komponenten verspricht zwei Vorteile:
Erstes kann Sprachsynthese dadurch ohne die Anbindung eines Drittanbieters umgesetzt werden.
Zweitens ist die Kompatibilität mit iOS15 Clients garantiert und die Integration der Funktionen ohne externe Bibliotheken möglich~\cite{ios_speech_synthesis}.
Gleichzeitig entsteht damit aber eine starke Bindung an Apple als Dienstleister für Sprachsynthese.
Sollte die Funktion in künftigen Versionen nicht mehr unterstützt werden, müsste die ganze Integration von Sprachsynthese neu evaluiert und implementiert werden.
Weiter reduziert diese Variante die Flexibilität der Systemarchitektur.
Mit der Verwendung der iOS Standardbibliothek für Sprachsynthese, muss die Anbindung an den Dienstleister direkt in der iOS Applikation umgesetzt werden.
Dies ist insbesondere ein Nachteil, da für dieselbe Funktionalität in zukünftigen Android Clients ein anderer Dienstleister verwendet werden muss.
Eine einheitliche Integration der Sprachsynthese in zukünftigen Plattformen ist deshalb nicht möglich, wenn Apple Speech Synthesis verwendet wird.

\subsubsection{Amazon Polly}

Die Anforderung U19\footnote{Siehe Kapitel 3.1.3} fordert, dass für Infrastruktur und Dienstleistungen wo möglich Amazon Webservices verwendet wird.
Mit dem Amazon Polly bietet Amazon Webservices einen Dienst, welcher Text in Sprachdaten verwandeln kann~\cite{aws_polly}.
Amazon Polly stellt Libraries für iOS~\cite{aws_polly_ios}, Android~\cite{aws_polly_sdks} und für Java zur Verfügung~\cite{aws_polly_java}.
Es kann damit sowohl direkt in native mobile Applikationen als auch in den Cloudservice integriert werden.

Die iOS Library von Amazon Polly ermöglicht es, die Anbindung des externen Sprachsyntheseproviders direkt im Mobile Client zu implementieren~\cite{aws_polly_ios}.
Diese Lösung kann für zukünftige Android Clients analog mit der Android Library für Aws Polly umgesetzt werden.
Die starke Bindung zu Apple als Dienstleister für Sprachsynthese entfällt durch diese Lösung.
Es wird allerdings eine starke Bindung zu Amazon Polly als Dienstleister geschaffen.
Ein Wechsel des Anbieters bleibt auch in dieser Variante aufwändig.
Insbesondere, wenn in Zukunft Clients für weitere Plattformen angeboten werden.

Mit der Java Bibliothek von Amazon Polly kann die Anbindung des Sprachsyntheseproviders im Cloudservice vorgenommen werden.
Dadurch ist es möglich im Cloudservice eine Schnittstelle zu implementieren, welche den Bezug von Sprachdaten für Benachrichtigungen erlaubt.
Diese Schnittstelle kann in die bestehende API des Cloudservices integriert werden.
Damit können alle Clients die Sprachdaten über dieselbe Schnittstelle beziehen.
Caching von Sprachdaten kann sowohl auf Serverseite als auch auf Clientseite implementiert werden.
Die Integration von Sprachsynthese in die API des Cloudservices ermöglicht es weiter, den gewählten Dienstleister in Zukunft einfach und ohne die Clients anzupassen auszutauschen.
Gleichzeitig hat diese Variante den Nachteil, dass der Cloudservice komplexer wird.
Durch die Integration von Sprachsynthese wird ein neues Umsystem angebunden.
Die Komplexität des Systems als Ganzes, wächst dadurch in jedem Fall.
Wie stark die Komplexität des Systems zunimmt, kann jedoch minimiert werden, indem die neue Funktionalität eng gekapselt wird.
Sie kann so umgesetzt werden, dass sie unabhängig vom restlichen System bleibt und alle nötigen Daten über die Schnittstellen anderer Module bezieht.

Als dritte Option für die Integration von Amazon Polly kann AWS Lambda verwendet werden~\cite{aws_polly}.
AWS Lambda erlaubt es Funktionalität ohne Serverinstanz auszuführen.
Der Bezieher der Dienstleistung definiert die auszuführende Funktionalität und bestimmt, wann diese ausgeführt wird.
Die Entscheidung, wie die Funktionalität ausgeführt wird, wird dabei an AWS übergeben~\cite{aws_lambda}.
Dies erlaubt es Funktionalität in ein System zu integrieren, ohne Serverinfrastruktur aufbauen zu müssen.

Die Integration von Amazon Polly über AWS Lambda kann für Praxisruf in zwei Verarbeitungsschritten implementiert werden.
In einem ersten Schritt werden die zu synthetisierenden Daten geladen und an Amazon Polly gesendet.
Anschliessend werden die Resultate, die Amazon Polly liefert persistiert.
Die Abfrage von Sprachdaten kann in diesem Fall ebenfalls in die API des Cloudservices integriert werden.
Dazu muss der Cloudservice auf die persistierten Sprachdaten zugreifen und einen Endpunkt anbieten, um diese abzufragen.
Dieser Ansatz bringt zwei Nachteile mit sich.
Erstens müssen die synthetisierten Sprachdaten zwingend ausserhalb des Mobile Clients persistiert werden.
Zweitens wird eine stärkere Bindung an Amazon als Dienstleister geschaffen, weil die Anbindung der Sprachsynthese über proprietäre Funktionalität von Amazon implementiert wird.
Gleichzeitig bietet der Ansatz den Vorteil, dass weniger Infrastruktur benötigt wird, da die Abfrage an AWS Polly ohne dedizierten Server abgesetzt werden kann.
Um eine einheitliche API zu bieten, muss das System aber auch in diesem Fall erweitert werden, um eine entsprechende Schnittstelle anbieten zu können.

\subsubsection{Entscheidung}

Die Sprachsynthese wird durch die Anbindung des externen Anbieters Amazon Polly umgesetzt.
Der Cloudservice übernimmt die Kommunikation mit Amazon Polly und bietet eine Schnittstelle, über welche Clients Audiodaten beziehen können.
Diese Schnittstelle wird in die API des Cloudservices integriert.
Die Anbindung an Amazon Polly wird dabei direkt im Cloudservice implementiert und nicht über AWS Lambda gelöst.
So kann die bestehende Infrastruktur des Cloudservices übernommen werden und es ist nicht notwendig die Sprachdaten ausserhalb von Mobile Clients zu persistieren.
Dies erlaubt es einerseits ein Clientseitiges Cache für Sprachdaten zu implementieren und dadurch Netzwerkanfragen zu minimieren.
Es erlaubt es weiter, nur Sprachdaten zu synthetisieren, welche tatsächlich von Clients angefragt werden.

Durch diesen Ansatz wird die Abhängigkeit zu einzelnen Anbieter minimiert.
Die Anbindung von Sprachsynthese kann für alle Client-Plattformen einheitlich umgesetzt werden.
Dies macht die gewählte Variante zukunftssicher und bietet grosse Flexibilität für den Betrieb.
Der Zuwachs an Komplexität durch die Anbindung eines neuen Umsystems wird durch entsprechende Kapselung der Funktionalität in ein eigenes Modul minimiert.

\clearpage
